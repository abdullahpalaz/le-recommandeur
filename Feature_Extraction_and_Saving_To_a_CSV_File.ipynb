{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Extraction_and_Saving_To_a_CSV_File.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyer37HBAKse"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eyed3\n",
        "import glob\n",
        "import time\n",
        "import eyed3\n",
        "import os\n",
        "import librosa"
      ],
      "metadata": {
        "id": "CHuQ3vniAxhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import IPython.display as ipd\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "from os import path\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "zjvdVd02Axj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import csv\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "#Keras\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import glob"
      ],
      "metadata": {
        "id": "K0oWZVwkAxmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating a dataset\n",
        "header = 'song_name chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "for i in range(1, 21):\n",
        "    header += f' mfcc{i}'\n",
        "header += \" polarity\"\n",
        "header = header.split()\n",
        "header"
      ],
      "metadata": {
        "id": "C_USA4sTAxom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "jzTrwx-3Axq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity(lyric):\n",
        "    if(sid.polarity_scores(lyric)['pos'] - sid.polarity_scores(lyric)['neg'] > 0.05 ):\n",
        "        return(1)\n",
        "    else:\n",
        "        return(0)"
      ],
      "metadata": {
        "id": "3f7wzJEsA3gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fldr in os.listdir('/content/drive/MyDrive/dataset'):\n",
        "  print(fldr)"
      ],
      "metadata": {
        "id": "i2B3W00rA3jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sayac = 1\n",
        "for folder_name in os.listdir('/content/drive/MyDrive/dataset')[12:]:\n",
        "    onlyfiles = [f for f in listdir(\"/content/drive/MyDrive/dataset/\" + folder_name) if isfile(join(\"/content/drive/MyDrive/dataset/\" + folder_name, f))]\n",
        "    onlyfiles.sort(key=lambda v: v.upper())\n",
        "    matching = [s for s in onlyfiles if \"lyrics.csv\" in s]\n",
        "    onlyfiles.remove(matching[0])\n",
        "    lyrics = pd.read_csv(\"/content/drive/MyDrive/dataset/\" + folder_name + \"/\" + matching[0], index_col=False, header=None)\n",
        "    soz_sayaci = 0\n",
        "    for song_name in onlyfiles:\n",
        "        y, sr = librosa.load(glob.glob('/content/drive/MyDrive/dataset/' + folder_name + \"/\" + song_name)[0], duration=90)  \n",
        "    \n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
        "        if(type(lyrics[0].values[soz_sayaci]) == float):\n",
        "            sentiment = 0\n",
        "        else:\n",
        "            sentiment = polarity(lyrics[0].values[soz_sayaci])\n",
        "        for e in mfcc:\n",
        "            to_append += f' {np.mean(e)}'\n",
        "        file1 = open('/content/drive/MyDrive/last_dataframe/dataframe.csv', 'a', newline='')\n",
        "        with file1:\n",
        "            writer = csv.writer(file1)\n",
        "            writer.writerow([song_name] + to_append.split() + [sentiment])\n",
        "\n",
        "\n",
        "        print(\"BİTTİ\", sayac)\n",
        "        sayac += 1\n",
        "        soz_sayaci +=1\n",
        "\n",
        "    \n",
        "file1.close()"
      ],
      "metadata": {
        "id": "Fq_OdWcqA3nW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}